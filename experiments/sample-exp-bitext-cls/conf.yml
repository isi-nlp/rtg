environment:
  data: data/trec

model_args:
  model_id: hf:facebook/nllb-200-distilled-600M
  src_vocab: 256204
  tgt_vocab: 6
  pretrained: true
model_type: bitext-classifier-comet

optimizer:
  name: adam
  args:
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    lr: 0.1

schedule:
  name: noam
  args:
    constant: 2
    warmup: 8000
    model_dim: 128

criterion:
  name: sparse_cross_entropy

prep:
  max_types: 4000
  pieces: bpe
  codec_lib: nlcodec
  shared_vocab: false
  src_len: 100
  tgt_len: 100
  # STDIN: seq1 \t seq2 \t label
  #train_src: stdin:text:1,stdin:text:2
  #train_tgt: stdin:text:3
  train_src: ${data}/train.text.tsv
  train_tgt: ${data}/train.coarse
  truncate: true
  valid_src: ${data}valid.text.tsv
  valid_tgt: ${data}/valid.coarse
  mono_tgt:
    - ${data}/train.coarse
  mono_src:
    - ${data}/train.text.tsv
tester:
  suite:
    valid:
    - ${data}/valid.text
    - ${data}/valid.coarse
  ensemble: 2
  batch_size: 6000
  max_len: 256

trainer:
  batch_size: [1024, 8]
  check_point: 250
  keep_models: 10
  steps: 3000
  sort_by: random
updated_at: '2023-05-15T19:30:30.859040'
rtg_version:
  previous:
  last_worked: 0.7.3-dev
