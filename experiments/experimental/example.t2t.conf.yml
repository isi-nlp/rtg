
# reference https://github.com/tensorflow/tensor2tensor/blob/fb5082920c1a649bacb67938b8ebc13fad78604f/tensor2tensor/models/transformer.py#L1539
model_args:
  ff_size: 2048
  hid_size: 512
  n_heads: 8
  n_layers: 6
  dropout: 0.1
model_type: t2t
optim:
  args:
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    lr: 0.1
    warmup_steps: 8000
    label_smoothing: 0.1
  name: ADAM
trainer:
  steps: 128000
  check_point: 1000
  keep_models: 10
  batch_size: 2048

tester:
  decoder:
    beam_size: 4
    max_len: 60
  suit:
    valid:
      - data/valid.src
      - data/valid.tgt
    test:
      - data/test.src
      - data/test.tgt

prep:
  mono_src: []
  mono_tgt: []
  src_len: 500
  tgt_len: 500
  train_src: data/train.src
  train_tgt: data/train.tgt
  truncate: true
  valid_src: data/valid.src
  valid_tgt: data/valid.tgt
  shared_vocab: true
  max_types: 16000
  pieces: unigram
  no_split_toks:
    - <tok1>
    - <tok2>
  finetune_src: data/finetune.src
  finetune_tgt: data/finetune.tgt

updated_at: '2018-07-25T15:53:18.379150'

