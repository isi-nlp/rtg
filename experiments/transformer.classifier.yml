model_args:
  src_vocab: 2751
  tgt_vocab: 14
  enc_layers: 3
  hid_size: 128
  ff_size: 256
  n_heads: 2
  attn_bias: true
  attn_dropout: 0.1
  dropout: 0.2
  activation: relu
model_type: tfmcls
__parent:
  experiment: <path/to/experiment/dir>
  vocab:
    src: src            # for separate vocabs
    #tgt: tgt
  shrink: true        # shrink vocabularies and embeddings to child data
                      # specified in train_src and mono_src
  model:
    args: true          # update/overwrite the model_args of child with the parent
    ensemble: 5         # how many checkpoints of parent to ensemble, to obtain initial state

optimizer:
  name: adam
  args:
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    lr: 0.1
    weight_decay: 0

schedule:
  name: noam
  args:
    constant: 2
    warmup: 4000
    model_dim: 128

criterion:
  name: cross_entropy
  # no args

prep:
  max_types: 4000
  pieces: bpe
  codec_lib: nlcodec
  shared_vocab: false
  src_len: 256
  tgt_len: 100
  train_src: tests/test-data/dbpedia/train.text
  train_tgt: tests/test-data/dbpedia/train.label
  truncate: true
  valid_src: tests/test-data/dbpedia/valid.text
  valid_tgt: tests/test-data/dbpedia/valid.label
tester:
  suite:
    valid:
    - tests/test-data/dbpedia/valid.text
    - tests/test-data/dbpedia/valid.label
  ensemble: 2
  batch_size: 6000
  max_len: 256

trainer:
  batch_size: 1024
  check_point: 250
  keep_models: 10
  steps: 3000
  sort_by: random
updated_at: '2021-07-31T19:29:42.341722'
